{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 Practice: Pandas Part 2\n",
    "\n",
    "Use this notebook to follow along with the lesson in the corresponding lesson notebook: [L04-Pandas_Part2-Lesson.ipynb](./L04-Pandas_Part2-Lesson.ipynb).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Follow along with the teaching material in the lesson. Throughout the tutorial sections labeled as \"Tasks\" are interspersed and indicated with the icon: ![Task](http://icons.iconarchive.com/icons/sbstnblnd/plateau/16/Apps-gnome-info-icon.png). You should follow the instructions provided in these sections by performing them in the practice notebook.  When the tutorial is completed you can turn in the final practice notebook. For each task, use the cell below it to write and test your code.  You may add additional cells for any task as needed or desired.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a: Setup\n",
    "\n",
    "- import pandas\n",
    "- re-create the `df` data frame\n",
    "- re-create the `iris_df` data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha beta\n",
      "0      0    a\n",
      "1      1    b\n",
      "2      2    c\n",
      "3      3    d\n",
      "4      4    e\n",
      "***************************************************************************\n",
      "     sepal_length  sepal_width  petal_length  petal_width    species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(\n",
    "    {'alpha': [0, 1, 2, 3, 4],\n",
    "     'beta': ['a', 'b', 'c', 'd', 'e']})\n",
    "print(df)\n",
    "print(\"*\"*75)\n",
    "iris_df=pd.read_csv('iris.xls')\n",
    "print(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a: Inserting Columns\n",
    "\n",
    "+ Create a copy of the `df` dataframe.\n",
    "+ Add a new column named \"delta\" to the copy that consists of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original:\n",
      "   alpha beta\n",
      "0      0    a\n",
      "1      1    b\n",
      "2      2    c\n",
      "3      3    d\n",
      "4      4    e\n",
      "***************************************************************************\n",
      "The copy:\n",
      "   alpha beta     delta\n",
      "0      0    a  0.700385\n",
      "1      1    b  0.249349\n",
      "2      2    c  0.369210\n",
      "3      3    d  0.535715\n",
      "4      4    e  0.834701\n"
     ]
    }
   ],
   "source": [
    "df_copy=df.copy()\n",
    "df_copy['delta']=np.random.random([5])\n",
    "print('The original:')\n",
    "print(df)\n",
    "print('*'*75)\n",
    "print('The copy:')\n",
    "print(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a: Missing Data\n",
    "\n",
    "+ Create two new copies of the `df` dataframe:\n",
    "+ Add a new column to both that has missing values.\n",
    "+ In one copy, replace missing values with a value of your choice.\n",
    "+ In the other copy, drop rows with `NaN` values.\n",
    "+ Print both arrays to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha beta  New\n",
      "0      0    a  1.0\n",
      "1      1    b  2.0\n",
      "2      2    c  3.0\n",
      "3      3    d  NaN\n",
      "4      4    e  NaN\n",
      "***************************************************************************\n",
      "   alpha beta  New\n",
      "0      0    a  1.0\n",
      "1      1    b  2.0\n",
      "2      2    c  3.0\n",
      "***************************************************************************\n",
      "   alpha beta  New\n",
      "0      0    a  6.0\n",
      "1      1    b  7.0\n",
      "2      2    c  8.0\n",
      "3      3    d  NaN\n",
      "4      4    e  NaN\n",
      "***************************************************************************\n",
      "   alpha beta  New\n",
      "0      0    a  6.0\n",
      "1      1    b  7.0\n",
      "2      2    c  8.0\n",
      "3      3    d  0.0\n",
      "4      4    e  0.0\n"
     ]
    }
   ],
   "source": [
    "clone1=df.copy()\n",
    "clone2=df.copy()\n",
    "clone1['New']=pd.Series([1,2,3])\n",
    "clone2['New']=pd.Series([6,7,8])\n",
    "print(clone1)\n",
    "print('*'*75)\n",
    "clone1.dropna(inplace=True)\n",
    "print(clone1)\n",
    "print('*'*75)\n",
    "print(clone2)\n",
    "clone2.fillna(0,inplace=True)\n",
    "print('*'*75)\n",
    "print(clone2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a: Operations\n",
    "<span style=\"float:right; margin-left:10px; clear:both;\">![Task](./media/task-icon.png)</span>\n",
    "\n",
    "View the [Computational tools](https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html) and [statistical methods](https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html#method-summary) documentation.\n",
    "Using the list of operational functions choose five functions to use with the iris data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "sepal_length    150\n",
      "sepal_width     150\n",
      "petal_length    150\n",
      "petal_width     150\n",
      "species         150\n",
      "dtype: int64\n",
      "***************************************************************************\n",
      "              sepal_length  sepal_width  petal_length  petal_width\n",
      "sepal_length      1.000000    -0.109369      0.871754     0.817954\n",
      "sepal_width      -0.109369     1.000000     -0.420516    -0.356544\n",
      "petal_length      0.871754    -0.420516      1.000000     0.962757\n",
      "petal_width       0.817954    -0.356544      0.962757     1.000000\n",
      "***************************************************************************\n",
      "sepal_length    0.828066\n",
      "sepal_width     0.433594\n",
      "petal_length    1.764420\n",
      "petal_width     0.763161\n",
      "dtype: float64\n",
      "***************************************************************************\n",
      "sepal_length    0.685694\n",
      "sepal_width     0.188004\n",
      "petal_length    3.113179\n",
      "petal_width     0.582414\n",
      "dtype: float64\n",
      "***************************************************************************\n",
      "              sepal_length  sepal_width  petal_length  petal_width\n",
      "sepal_length      0.685694    -0.039268      1.273682     0.516904\n",
      "sepal_width      -0.039268     0.188004     -0.321713    -0.117981\n",
      "petal_length      1.273682    -0.321713      3.113179     1.296387\n",
      "petal_width       0.516904    -0.117981      1.296387     0.582414\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*'*75)\n",
    "print(iris_df.count())\n",
    "print('*'*75)\n",
    "print(iris_df.corr())\n",
    "print('*'*75)\n",
    "print(iris_df.std())\n",
    "print('*'*75)\n",
    "print(iris_df.var())\n",
    "print('*'*75)\n",
    "print(iris_df.cov())\n",
    "print('*'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b:  Apply\n",
    "\n",
    "Practice using `apply` on either the `df` or `iris_df` data frames using any two functions of your choice other than `print`, `type`, and `np.sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           False        False         False        False    False\n",
      "1           False        False         False        False    False\n",
      "2           False        False         False        False    False\n",
      "3           False        False         False        False    False\n",
      "4           False        False         False        False    False\n",
      "..            ...          ...           ...          ...      ...\n",
      "145         False        False         False        False    False\n",
      "146         False        False         False        False    False\n",
      "147         False        False         False        False    False\n",
      "148         False        False         False        False    False\n",
      "149         False        False         False        False    False\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "***************************************************************************\n",
      "0      (5,)\n",
      "1      (5,)\n",
      "2      (5,)\n",
      "3      (5,)\n",
      "4      (5,)\n",
      "       ... \n",
      "145    (5,)\n",
      "146    (5,)\n",
      "147    (5,)\n",
      "148    (5,)\n",
      "149    (5,)\n",
      "Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(iris_df.apply(pd.isna,axis=1))\n",
    "print('*'*75)\n",
    "print(iris_df.apply(np.shape,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c.  Occurances\n",
    "Ientify the number of occurances for each species (virginica, versicolor, setosa) in the `iris_df` object.  *Hint*: the `value_counts` function only works on a `pd.Series` object, not on the full data frame.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versicolor    50\n",
       "virginica     50\n",
       "setosa        50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['species'].value_counts() #Just specify the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5a: String Methods\n",
    "\n",
    "+ Create a list of five strings that represent dates in the form YYYY-MM-DD (e.g. 2020-02-20 for Feb 20th, 2020).\n",
    "+ Add this list of dates as a new column in the `df` dataframe.\n",
    "+ Now split the date into 3 new columns with one column representing the year, another the month and another they day.\n",
    "+ Combine the values from columns `alpha` and `beta` into a new column where the values are spearated with a colon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2020-02-20\n",
      "1    2020-02-21\n",
      "2    2020-02-22\n",
      "3    2020-02-23\n",
      "4    2020-02-24\n",
      "dtype: object\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "   alpha beta       dates\n",
      "0      0    a  2020-02-20\n",
      "1      1    b  2020-02-21\n",
      "2      2    c  2020-02-22\n",
      "3      3    d  2020-02-23\n",
      "4      4    e  2020-02-24\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "0    [2020, 02, 20]\n",
      "1    [2020, 02, 21]\n",
      "2    [2020, 02, 22]\n",
      "3    [2020, 02, 23]\n",
      "4    [2020, 02, 24]\n",
      "Name: dates, dtype: object\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "   alpha beta       dates  Year Month Day Combined\n",
      "0      0    a  2020-02-20  2020    02  20      0:a\n",
      "1      1    b  2020-02-21  2020    02  21      1:b\n",
      "2      2    c  2020-02-22  2020    02  22      2:c\n",
      "3      3    d  2020-02-23  2020    02  23      3:d\n",
      "4      4    e  2020-02-24  2020    02  24      4:e\n"
     ]
    }
   ],
   "source": [
    "dates=pd.Series(['2020-02-20','2020-02-21','2020-02-22','2020-02-23','2020-02-24'])\n",
    "print(dates)\n",
    "print('|'*75)\n",
    "df['dates']=dates\n",
    "print(df)\n",
    "print('|'*75)\n",
    "print(df['dates'].str.split('-'))\n",
    "print('|'*75)\n",
    "df['Year'],df['Month'],df['Day']=df['dates'].str.split('-').str\n",
    "df['Combined']=df['alpha'].apply(str)+':'+df['beta']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6a: Concatenation by Rows\n",
    "+ Create the following dataframe\n",
    "```Python\n",
    "df1 = pd.DataFrame(\n",
    "    {'alpha': [0, 1, 2, 3, 4],\n",
    "     'beta': ['a', 'b', 'c', 'd', 'e']}, index = ['I1', 'I2' ,'I3', 'I4', 'I5'])\n",
    "```\n",
    "+ Create a new dataframe named `df2` with column names \"delta\" and \"gamma\" that contins 5 rows with some index names that overlap with the `df1` dataframe and some that do not.\n",
    "+ Concatenate the two dataframes by rows and print the result.\n",
    "+ You should see the two have combined one after the other, but there should also be missing values added. \n",
    "+ Explain why there are missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alpha beta\n",
      "I1      0    a\n",
      "I2      1    b\n",
      "I3      2    c\n",
      "I4      3    d\n",
      "I5      4    e\n",
      "***************************************************************************\n",
      "    delta beta\n",
      "I5      4    e\n",
      "I6     11    y\n",
      "I7     12    c\n",
      "I8      3    w\n",
      "I9     14    x\n",
      "***************************************************************************\n",
      "    alpha beta  delta\n",
      "I1    0.0    a    NaN\n",
      "I2    1.0    b    NaN\n",
      "I3    2.0    c    NaN\n",
      "I4    3.0    d    NaN\n",
      "I5    4.0    e    NaN\n",
      "I5    NaN    e    4.0\n",
      "I6    NaN    y   11.0\n",
      "I7    NaN    c   12.0\n",
      "I8    NaN    w    3.0\n",
      "I9    NaN    x   14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paige\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'alpha': [0, 1, 2, 3, 4],'beta': ['a', 'b', 'c', 'd', 'e']}, index = ['I1', 'I2' ,'I3', 'I4', 'I5'])\n",
    "df2=pd.DataFrame({'delta':[4,11,12,3,14],'beta':['e','y','c','w','x']},index=['I5','I6','I7','I8','I9'])\n",
    "print(df1)\n",
    "print('*'*75)\n",
    "print(df2)\n",
    "print('*'*75)\n",
    "list_of_df=[df1,df2]\n",
    "concat=pd.concat(list_of_df)\n",
    "print(concat)\n",
    "#These values are misisng because all dataframes do not have the same columns\n",
    "#concat is just pasting the data to the end of the first dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6b: Concatenation by Columns\n",
    "\n",
    "Using the same dataframes, df1 and df2, from Task 6a practice:\n",
    "+ Concatenate the two by columns\n",
    "+ Add a \"delta\" column to `df1` and concatenate by columns such that there are 5 columns in the merged dataframe.\n",
    "+ Respond in writing to this question (add a new 'raw' cell to contain your answer). What will happen if using you had performed an inner join while concatenating?  \n",
    "+ Try the concatenation with the inner join to see if you are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alpha beta    delta  delta beta\n",
      "I1    0.0    a      cat    NaN  NaN\n",
      "I2    1.0    b      dog    NaN  NaN\n",
      "I3    2.0    c    mouse    NaN  NaN\n",
      "I4    3.0    d  hamster    NaN  NaN\n",
      "I5    4.0    e    snake    4.0    e\n",
      "I6    NaN  NaN      NaN   11.0    y\n",
      "I7    NaN  NaN      NaN   12.0    c\n",
      "I8    NaN  NaN      NaN    3.0    w\n",
      "I9    NaN  NaN      NaN   14.0    x\n",
      "***************************************************************************\n",
      "    alpha beta    delta  delta beta\n",
      "I1    0.0    a      cat    NaN  NaN\n",
      "I2    1.0    b      dog    NaN  NaN\n",
      "I3    2.0    c    mouse    NaN  NaN\n",
      "I4    3.0    d  hamster    NaN  NaN\n",
      "I5    4.0    e    snake    4.0    e\n",
      "I6    NaN  NaN      NaN   11.0    y\n",
      "I7    NaN  NaN      NaN   12.0    c\n",
      "I8    NaN  NaN      NaN    3.0    w\n",
      "I9    NaN  NaN      NaN   14.0    x\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paige\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\paige\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>I5</td>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>snake</td>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha beta  delta  delta beta\n",
       "I5      4    e  snake      4    e"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.concat(list_of_df,axis=1) )#if you don't have overlapping index\n",
    "#names, you will not be able to concat properly\n",
    "df1['delta']=['cat','dog','mouse','hamster','snake']\n",
    "print('*'*75)\n",
    "print(pd.concat(list_of_df,axis=1))\n",
    "print('*'*75)\n",
    "pd.concat(list_of_df,axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I think if we use inner join with these dataframes, I am going to end up with a dataframe that contains one row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6c: Concat and append data frames\n",
    "<span style=\"float:right; margin-left:10px; clear:both;\">![Task](./media/task-icon.png)</span>\n",
    "\n",
    "+ Create a new 5x5 dataframe full of random numbers.\n",
    "+ Create a new 5x10 dataframe full of 1's.\n",
    "+ Append one to the other and print it.\n",
    "+ Append a single Series of zeros to the end of the appended dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4\n",
      "0  4.601823  9.313346  2.633427  3.897216  4.408691\n",
      "1  4.174852  6.200852  4.022953  7.493926  3.493446\n",
      "2  7.512218  6.932527  0.304936  3.103871  4.168875\n",
      "3  6.474867  0.768932  4.717452  8.982995  8.442572\n",
      "4  9.925138  5.642729  6.262936  4.638503  0.324140\n",
      "***************************************************************************\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "***************************************************************************\n",
      "          0         1         2         3         4    5    6    7    8    9\n",
      "0  4.601823  9.313346  2.633427  3.897216  4.408691  NaN  NaN  NaN  NaN  NaN\n",
      "1  4.174852  6.200852  4.022953  7.493926  3.493446  NaN  NaN  NaN  NaN  NaN\n",
      "2  7.512218  6.932527  0.304936  3.103871  4.168875  NaN  NaN  NaN  NaN  NaN\n",
      "3  6.474867  0.768932  4.717452  8.982995  8.442572  NaN  NaN  NaN  NaN  NaN\n",
      "4  9.925138  5.642729  6.262936  4.638503  0.324140  NaN  NaN  NaN  NaN  NaN\n",
      "5  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "6  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "7  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "8  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "9  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "***************************************************************************\n",
      "          0         1         2         3         4    5    6    7    8    9\n",
      "0  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "1  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "2  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "3  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "4  1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
      "5  4.601823  9.313346  2.633427  3.897216  4.408691  NaN  NaN  NaN  NaN  NaN\n",
      "6  4.174852  6.200852  4.022953  7.493926  3.493446  NaN  NaN  NaN  NaN  NaN\n",
      "7  7.512218  6.932527  0.304936  3.103871  4.168875  NaN  NaN  NaN  NaN  NaN\n",
      "8  6.474867  0.768932  4.717452  8.982995  8.442572  NaN  NaN  NaN  NaN  NaN\n",
      "9  9.925138  5.642729  6.262936  4.638503  0.324140  NaN  NaN  NaN  NaN  NaN\n",
      "***************************************************************************\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.601823</td>\n",
       "      <td>9.313346</td>\n",
       "      <td>2.633427</td>\n",
       "      <td>3.897216</td>\n",
       "      <td>4.408691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.174852</td>\n",
       "      <td>6.200852</td>\n",
       "      <td>4.022953</td>\n",
       "      <td>7.493926</td>\n",
       "      <td>3.493446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.512218</td>\n",
       "      <td>6.932527</td>\n",
       "      <td>0.304936</td>\n",
       "      <td>3.103871</td>\n",
       "      <td>4.168875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.474867</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>4.717452</td>\n",
       "      <td>8.982995</td>\n",
       "      <td>8.442572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.925138</td>\n",
       "      <td>5.642729</td>\n",
       "      <td>6.262936</td>\n",
       "      <td>4.638503</td>\n",
       "      <td>0.324140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4    5    6    7    8    9\n",
       "0   4.601823  9.313346  2.633427  3.897216  4.408691  NaN  NaN  NaN  NaN  NaN\n",
       "1   4.174852  6.200852  4.022953  7.493926  3.493446  NaN  NaN  NaN  NaN  NaN\n",
       "2   7.512218  6.932527  0.304936  3.103871  4.168875  NaN  NaN  NaN  NaN  NaN\n",
       "3   6.474867  0.768932  4.717452  8.982995  8.442572  NaN  NaN  NaN  NaN  NaN\n",
       "4   9.925138  5.642729  6.262936  4.638503  0.324140  NaN  NaN  NaN  NaN  NaN\n",
       "5   1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
       "6   1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
       "7   1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
       "8   1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
       "9   1.000000  1.000000  1.000000  1.000000  1.000000  1.0  1.0  1.0  1.0  1.0\n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_df=pd.DataFrame(np.random.random([5,5])*10)\n",
    "ones_df=pd.DataFrame(np.ones([5,10]))\n",
    "print(random_df)\n",
    "print('*'*75)\n",
    "print(ones_df)\n",
    "print('*'*75)\n",
    "appended=random_df.append(ones_df,ignore_index=True)\n",
    "print(appended)\n",
    "print('*'*75)\n",
    "print(ones_df.append(random_df,ignore_index=True))\n",
    "print('*'*75)\n",
    "zeroes=pd.Series(np.zeros(10))\n",
    "print(zeroes)\n",
    "appended.append(zeroes,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6d: Grouping\n",
    "\n",
    "Demonstrate a `groupby`.\n",
    "\n",
    "+ Create a new column with the label \"region\" in the iris data frame. This column will indicates geographic regions of the US where measurments were taken. Values should include:  'Southeast', 'Northeast', 'Midwest', 'Southwest', 'Northwest'. Use these randomly.\n",
    "+ Use `groupby` to get a new data frame of means for each species in each region.\n",
    "+ Add a `dev_stage` column by randomly selecting from the values \"early\" and \"late\".\n",
    "+ Use `groupby` to get a new data frame of means for each species,in each region and each development stage.\n",
    "+ Use the `count` function (just like you used the `mean` function) to identify how many rows in the table belong to each combination of species + region + developmental stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width    species  \\\n",
      "0             5.1          3.5           1.4          0.2     setosa   \n",
      "1             4.9          3.0           1.4          0.2     setosa   \n",
      "2             4.7          3.2           1.3          0.2     setosa   \n",
      "3             4.6          3.1           1.5          0.2     setosa   \n",
      "4             5.0          3.6           1.4          0.2     setosa   \n",
      "..            ...          ...           ...          ...        ...   \n",
      "145           6.7          3.0           5.2          2.3  virginica   \n",
      "146           6.3          2.5           5.0          1.9  virginica   \n",
      "147           6.5          3.0           5.2          2.0  virginica   \n",
      "148           6.2          3.4           5.4          2.3  virginica   \n",
      "149           5.9          3.0           5.1          1.8  virginica   \n",
      "\n",
      "        region dev_stage  \n",
      "0    Northwest     early  \n",
      "1    Southeast      late  \n",
      "2    Southeast     early  \n",
      "3    Northeast      late  \n",
      "4    Southeast     early  \n",
      "..         ...       ...  \n",
      "145  Northwest      late  \n",
      "146  Northeast      late  \n",
      "147  Northeast     early  \n",
      "148  Northwest      late  \n",
      "149  Southeast     early  \n",
      "\n",
      "[150 rows x 7 columns]\n",
      "***************************************************************************\n",
      "                                sepal_length  sepal_width  petal_length  \\\n",
      "species    region    dev_stage                                            \n",
      "setosa     Midwest   early          5.180000     3.540000      1.540000   \n",
      "                     late           4.950000     3.500000      1.483333   \n",
      "           Northeast early          5.125000     3.475000      1.575000   \n",
      "                     late           4.800000     3.100000      1.366667   \n",
      "           Northwest early          5.057143     3.442857      1.528571   \n",
      "                     late           4.825000     3.025000      1.375000   \n",
      "           Southeast early          4.887500     3.437500      1.362500   \n",
      "                     late           4.775000     3.250000      1.525000   \n",
      "           Southwest early          5.125000     3.425000      1.450000   \n",
      "                     late           5.280000     3.720000      1.440000   \n",
      "versicolor Midwest   early          6.066667     2.566667      4.200000   \n",
      "                     late           6.200000     2.200000      4.500000   \n",
      "           Northeast early          5.800000     2.700000      4.100000   \n",
      "                     late           6.250000     2.700000      4.383333   \n",
      "           Northwest early          5.783333     2.866667      4.233333   \n",
      "                     late           5.930000     2.810000      4.350000   \n",
      "           Southeast early          5.566667     2.900000      4.200000   \n",
      "                     late           5.640000     2.640000      4.020000   \n",
      "           Southwest early          6.100000     2.900000      4.450000   \n",
      "                     late           6.133333     2.900000      4.266667   \n",
      "virginica  Midwest   early          6.585714     3.085714      5.614286   \n",
      "                     late           6.466667     2.900000      5.566667   \n",
      "           Northeast early          6.400000     2.866667      5.300000   \n",
      "                     late           6.483333     2.933333      5.366667   \n",
      "           Northwest early          7.050000     3.137500      5.937500   \n",
      "                     late           6.342857     2.900000      5.328571   \n",
      "           Southeast early          6.625000     3.050000      5.575000   \n",
      "                     late           6.450000     2.783333      5.416667   \n",
      "           Southwest early          6.800000     3.200000      5.650000   \n",
      "                     late           6.550000     2.875000      5.650000   \n",
      "\n",
      "                                petal_width  \n",
      "species    region    dev_stage               \n",
      "setosa     Midwest   early         0.360000  \n",
      "                     late          0.216667  \n",
      "           Northeast early         0.250000  \n",
      "                     late          0.166667  \n",
      "           Northwest early         0.257143  \n",
      "                     late          0.250000  \n",
      "           Southeast early         0.212500  \n",
      "                     late          0.200000  \n",
      "           Southwest early         0.325000  \n",
      "                     late          0.200000  \n",
      "versicolor Midwest   early         1.233333  \n",
      "                     late          1.500000  \n",
      "           Northeast early         1.216667  \n",
      "                     late          1.366667  \n",
      "           Northwest early         1.333333  \n",
      "                     late          1.360000  \n",
      "           Southeast early         1.466667  \n",
      "                     late          1.200000  \n",
      "           Southwest early         1.375000  \n",
      "                     late          1.350000  \n",
      "virginica  Midwest   early         2.085714  \n",
      "                     late          2.100000  \n",
      "           Northeast early         1.900000  \n",
      "                     late          1.950000  \n",
      "           Northwest early         2.125000  \n",
      "                     late          1.942857  \n",
      "           Southeast early         2.000000  \n",
      "                     late          2.000000  \n",
      "           Southwest early         2.050000  \n",
      "                     late          2.075000  \n",
      "***************************************************************************\n",
      "                                sepal_length  sepal_width  petal_length  \\\n",
      "species    region    dev_stage                                            \n",
      "setosa     Midwest   early                 5            5             5   \n",
      "                     late                  6            6             6   \n",
      "           Northeast early                 4            4             4   \n",
      "                     late                  3            3             3   \n",
      "           Northwest early                 7            7             7   \n",
      "                     late                  4            4             4   \n",
      "           Southeast early                 8            8             8   \n",
      "                     late                  4            4             4   \n",
      "           Southwest early                 4            4             4   \n",
      "                     late                  5            5             5   \n",
      "versicolor Midwest   early                 3            3             3   \n",
      "                     late                  1            1             1   \n",
      "           Northeast early                 6            6             6   \n",
      "                     late                  6            6             6   \n",
      "           Northwest early                 6            6             6   \n",
      "                     late                 10           10            10   \n",
      "           Southeast early                 3            3             3   \n",
      "                     late                  5            5             5   \n",
      "           Southwest early                 4            4             4   \n",
      "                     late                  6            6             6   \n",
      "virginica  Midwest   early                 7            7             7   \n",
      "                     late                  3            3             3   \n",
      "           Northeast early                 3            3             3   \n",
      "                     late                  6            6             6   \n",
      "           Northwest early                 8            8             8   \n",
      "                     late                  7            7             7   \n",
      "           Southeast early                 4            4             4   \n",
      "                     late                  6            6             6   \n",
      "           Southwest early                 2            2             2   \n",
      "                     late                  4            4             4   \n",
      "\n",
      "                                petal_width  \n",
      "species    region    dev_stage               \n",
      "setosa     Midwest   early                5  \n",
      "                     late                 6  \n",
      "           Northeast early                4  \n",
      "                     late                 3  \n",
      "           Northwest early                7  \n",
      "                     late                 4  \n",
      "           Southeast early                8  \n",
      "                     late                 4  \n",
      "           Southwest early                4  \n",
      "                     late                 5  \n",
      "versicolor Midwest   early                3  \n",
      "                     late                 1  \n",
      "           Northeast early                6  \n",
      "                     late                 6  \n",
      "           Northwest early                6  \n",
      "                     late                10  \n",
      "           Southeast early                3  \n",
      "                     late                 5  \n",
      "           Southwest early                4  \n",
      "                     late                 6  \n",
      "virginica  Midwest   early                7  \n",
      "                     late                 3  \n",
      "           Northeast early                3  \n",
      "                     late                 6  \n",
      "           Northwest early                8  \n",
      "                     late                 7  \n",
      "           Southeast early                4  \n",
      "                     late                 6  \n",
      "           Southwest early                2  \n",
      "                     late                 4  \n"
     ]
    }
   ],
   "source": [
    "iris_df['region']=np.random.choice(['Southeast','Northeast','Midwest','Southwest','Northwest'],iris_df.shape[0])\n",
    "iris_df['dev_stage']=np.random.choice(['early','late'],iris_df.shape[0])\n",
    "#if you don't include iris_df.shape[0] everything is assigned the same region\n",
    "print(iris_df)\n",
    "print('*'*75)\n",
    "print(iris_df.groupby(['species','region','dev_stage']).mean())\n",
    "print('*'*75)\n",
    "print(iris_df.groupby(['species','region','dev_stage']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
